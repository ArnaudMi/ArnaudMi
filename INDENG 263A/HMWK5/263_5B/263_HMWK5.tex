\documentclass{article}


\usepackage{array}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{geometry}
\usepackage{stmaryrd}




\geometry{hmargin=2.5cm,vmargin=1.5cm}

\title{INDENG263A : Homework 4}
\author{Arnaud Minondo}

\begin{document}

\maketitle

\section*{Problem 52 : Taxi Driver}
Let $\pi$ be the stationary distribution of the location of the taxi. 
\\
$\pi$ verifies : 
$ \begin{array}{c}
    \pi_0 = 0.6\pi_0 + 0.3\pi_1\\
    \pi_1 = 0.4\pi_0 +0.7\pi_1\\
\end{array} 
\implies \pi_0 = \frac{3}{4} \pi_1
$, with $\pi_0+\pi_1 = 1$ we obtain : $\pi_0 = \frac{3}{7}, \pi_1 = \frac{4}{7}$
\\
Let G be the profit of the taxi driver in one trip : $\mathbb{E}(G) = \pi_0(0.6*6+0.4*12) + \pi_1(0.3*12+0.7*8) = 8.86$
\section*{Problem 64 : Branching process, Total number of individuals}
Branching process : $\forall n\in\mathbb{N} : Z_n\sim(P_0,P_1,P_2,...)$, $\forall k \in \mathbb{N}$, $\mathbb{P}(Z_n=k) = P_k$, $X_{n+1} = \sum_{i=1}^{X_n}Z_i$
\\
The total number of individuals that ever existed is : $N=\sum_{i=0}^\infty X_i$
\\
$\mathbb{E}(N|X_0=1) = \sum_{i=0}^\infty\mathbb{E}(X_i|X_0=1)$\\
Moreover : $\forall i \in \mathbb{N}$, $\mathbb{E}(X_i|X_0=1) = \mathbb{E}(\mathbb{E}(X_i|X_{i-1},X_0=1)) = \mathbb{E}(\mu X_{i-1}) = \mu\mathbb{E}(X_{i-1}) = \mu^i\mathbb{E}(X_0) = \mu^i$
\\
So  : $$\boxed{\mathbb{E}(N|X_0=1) = \sum_{i=0}^\infty \mu^i = \frac{1}{1-\mu}}$$
\\
If $X_0 = n$ : $\mathbb{E}(X_i|X_0=n) = \mu^i n$ so : $$\boxed{\mathbb{E}(N|X_0=n) = \frac{n}{1-\mu}}$$
\section*{Problem 66 : Branching process, $\pi_0$ derivation}
In the branching process : \begin{itemize}
    \item if $\mu>1$ then $\pi_0<1$ and $\pi_0 = \sum_{i=0}^\infty \pi_0^iP_i$.
    \item if $\mu = 1$ and $P_0 > 0$ then $\pi_0 = 1$
    \item if $\mu<1$ then $\pi_0 = 1$
\end{itemize}
\subsection*{(a)}
$\mu = \frac{3}{2}$ so $\pi_0<1$ and $\pi_0 = \frac{1}{4}+\frac{3}{4}\pi_0^2$ finally in the two possible solutions of this equation only one can be the value as $\pi_0<1$.
 $$\boxed{\pi_0 = \frac{2}{3}}$$
\subsection*{(b)}
$\mu = 1$ so $$\boxed{\pi_0 = 1}$$
\subsection*{(c)}
$\mu = \frac{3}{2}$, $\pi_0 = \frac{1}{6}+frac{1}{2}\pi_0+\frac{1}{3}\pi_0^3$ so $2\pi_0^3-3\pi_0+1 = 0$.\\
A trivial solution of this equation is $\pi_0 = 1$ which is impossible because $\mu > 1$. We can rewrite the equation as : $(\pi_0-1)(2\pi_0^2+2\pi_0-1) = 0$
and conclude that $2\pi_0^2+2\pi_0-1 = 0$. Finally : $$\boxed{\pi_0 = \frac{\sqrt{3}-1}{2}}$$
\section*{Problem Set}
\subsection*{Question 1}
\subsubsection*{(a)}
Let $A_w$ :``A wins the truel''
I assumed that all the players know all of the strenght of all other players. So that A and B are first shooting on C and C is shooting on B first.
There are three cases :\begin{itemize}
    \item A hits C and B v A, B starting
    \item A fails, B hits C and A v B, A starting 
    \item A fails, B fails and A v C, A starting
\end{itemize}
In the case where A and B are in duel with B starting : 
\\
$\mathbb{P}(A_w|\text{A v B, B starts}) = 1 - \frac{2}{3}\sum_{i=0}^\infty (\frac{2}{3}\frac{1}{3})^i = \frac{1}{7}$\\
\\
The same situation where A starts : 
\\
$\mathbb{P}(A_w|\text{A v B, A starts}) =\frac{1}{3}\sum_{i=0}^\infty (\frac{1}{3}\frac{2}{3})^i =\frac{3}{7}$
\\\\
The situation where A and C are in duel with A starting :
\\
$\mathbb{P}(A_w|\text{A v C, A starting}) = \frac{1}{3}$
\\\\
$\mathbb{P}(A_w) = \frac{1}{7}\mathbb{P}(\text{A v B, Bstarts}) + \frac{3}{7}\mathbb{P}(\text{A v B, A starts}) + \frac{1}{3}\mathbb{P}(\text{A v C, A starts}) = \frac{1}{7}\frac{1}{3} + \frac{3}{7}(\frac{2}{3})^2+ \frac{1}{3}\frac{2}{3}\frac{1}{3} = \frac{59}{189}$
\subsubsection*{(b)}
There is only two cases if A shoots into the ground on his first shot : \begin{itemize}
    \item B hits C and A versus B, A starting
    \item B fails and A versus C, A starting
\end{itemize}
So $\mathbb{P}(A_w |\text{A shoots into the ground on his first shot}) = \frac{2}{3}\frac{3}{7}+\frac{1}{3}\frac{1}{3} = \frac{25}{63}$
\subsection*{Question 2}
In the gambler's ruin problem : 
$\forall i\in \{1,2,...,N-1\}, P_i =
\begin{array}{cc}
    \frac{1-(\frac{q}{p})^i}{1-(\frac{q}{p})^N} & \text{if } p\neq \frac{1}{2}\\
    \frac{i}{N} & \text{if } p = \frac{1}{2}\\
\end{array}$
 where $P_i$ is the probability that the gambler reaches $N$ before 0 starting with $i$.
\\\\
Suppose : $i<j$ then $f_{ij}$ is the probability that the gambler reaches $j$ before reaching 0 starting from $i$ then it is just the same game but with j instead of N. 
\\
$$\boxed{f_{ij} =
\begin{array}{cc}
    \frac{1-(\frac{q}{p})^i}{1-(\frac{q}{p})^j} & \text{if } p\neq \frac{1}{2}\\
    \frac{i}{j} & \text{if } p = \frac{1}{2}\\
\end{array}}$$
\\\\
Suppose : $j<i$ then loosing has probability : $1-P_i = f_{ij}(1-P_j)$ because you have to go from i to j if you loose as $j<i$.
\\
So : $$\boxed{f_{ij} = \frac{1-P_i}{1-P_j} = \begin{array}{cc}
    \frac{(\frac{q}{p})^N-(\frac{q}{p})^i}{(\frac{q}{p})^N-(\frac{q}{p})^j}&\text{if } p \neq \frac{1}{2}\\
    \frac{N-i}{N-j}&\text{if } p = \frac{1}{2}\\
\end{array} }$$
\\
Suppose : $i=j$ : $$\boxed{f_{ii} = pf_{i+1,i}+qf_{i-1,i} = \begin{array}{cc}
    p\frac{(\frac{q}{p})^N-(\frac{q}{p})^{i+1}}{(\frac{q}{p})^N-(\frac{q}{p})^i} + q\frac{1-(\frac{q}{p})^{i-1}}{1-(\frac{q}{p})^i}&\text{if } p \neq \frac{1}{2}\\
    p\frac{N-i-1}{N-i}+q\frac{i-1}{i}&\text{if } p = \frac{1}{2}\\
\end{array}}$$
\subsection*{Question 3}
$s_{ii} = \frac{1}{1-f_{ii}}$ and $s_{ij} = f_{ij}s_{jj} = \frac{f_{ij}}{1-f_{jj}}$ where we know $f_{ij}$ and $f_{ii}$ after question 2.
\subsection*{Question 6}
Let $k\in\mathbb{N}$ and $Y_k\sim B(p)$ be a bernoulli process. $Y_k$ represents the outcome of a step, either back either forward.
\\
Let $\forall n \in \mathbb{N} $ : $X_{n+1} = \max(0, X_n+2Y_n-1)$.
\\\\
Let $(i,j)\in\mathbb{N}^2, i<j$, let $P_n$ :``$\forall k \in \mathbb{N},\mathbb{P}(X_{n} \leq k|X_0=i)\ge\mathbb{P}(X_n \leq k |X_0 = j)$''.
\\
As $\mathbb{P}(X_0\leq k|X_0 = i) = I(i \leq k) = I(i\leq k < j)+I(j\leq k) $ and $\forall k \in \mathbb{N} : I(i\leq k<j)\ge0$
\\
Then $\mathbb{P}(X_0\leq k | X_0=i)\ge \mathbb{P}(X_0\leq k|X_0=j)$ so $P_0$ is true.
\\\\
Let $n\in \mathbb{N}, P_n$ true : $\forall k \in \mathbb{N} \backslash\{0\}$ :
\\
$\mathbb{P}(X_{n+1}\leq k|X_0=i) = \mathbb{P}(X_n\leq k-1|X_0 = i)\mathbb{P}(Y_n = 1)+\mathbb{P}(X_n\leq k+1|X_0=i)\mathbb{P}(Y_n=-1)$
\\
$\ge \mathbb{P}(X_n\leq k-1|X_0 = j)\mathbb{P}(Y_n = 1)+\mathbb{P}(X_n\leq k+1|X_0=j)\mathbb{P}(Y_n=-1) = \mathbb{P}(X_{n+1}\leq k|X_0=j) $
\\
If $k = 0$ then both probability are $1$ and the inequality holds.
\\
So $P_{n+1}$ is true. We conclude that $\forall n \in \mathbb{N}, P_n$ is true.
\\
Our first intermediate result is : $X_n|X_0=i\leq_{\text{st}}X_n|X_0=j$.
\\\\
Now, we notice that knowing the start at the origin, $X_0=0$ then $X_1 = 1$ or $X_1=0$
\\
If $X_1 = 0$ : $X_{n+1}|X_1=0 \sim X_n|X_0 = 0$ and $X_{n+1}|(X_0 = 0) =_{\text{st}} X_n|(X_0=0) $
\\
If $X_1 = 1$ : $X_{n+1}|X_1 = 1 \sim X_n|X_0=1$ and $X_{n+1}|X_1 = 1\sim X_{n}|(X_0 = 1) \ge_{\text{st}} X_n|(X_0=0) $ because 1>0 using the first result.
\\
Finally :$$\boxed{X_{n+1}|X_0=0\ge_{\text{st}}X_n|X_0=0}$$
\end{document}